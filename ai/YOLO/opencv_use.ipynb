{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6bed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실시간 이미지 캡처 및 처리를 이해 opencv 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23c4796c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.52  Python-3.9.7 torch-1.13.1+cu116 CUDA:0 (NVIDIA GeForce RTX 4080 SUPER, 16375MiB)\n",
      "Setup complete  (16 CPUs, 31.9 GB RAM, 483.1/930.8 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "\n",
    "ultralytics.checks() # 실행환경 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21483156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[183, 171, 171],\n",
       "        [199, 187, 187],\n",
       "        [204, 192, 192],\n",
       "        ...,\n",
       "        [206, 180, 164],\n",
       "        [202, 176, 160],\n",
       "        [206, 180, 164]],\n",
       "\n",
       "       [[187, 175, 175],\n",
       "        [193, 181, 181],\n",
       "        [197, 185, 185],\n",
       "        ...,\n",
       "        [206, 180, 164],\n",
       "        [205, 179, 163],\n",
       "        [211, 185, 169]],\n",
       "\n",
       "       [[199, 187, 187],\n",
       "        [197, 185, 185],\n",
       "        [199, 187, 187],\n",
       "        ...,\n",
       "        [211, 185, 169],\n",
       "        [209, 183, 167],\n",
       "        [211, 185, 169]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   6,  10],\n",
       "        [  0,   8,  12],\n",
       "        [  5,  17,  19],\n",
       "        ...,\n",
       "        [  4,  18,  24],\n",
       "        [  4,  18,  24],\n",
       "        [ 14,  28,  34]],\n",
       "\n",
       "       [[  0,  11,  13],\n",
       "        [  0,  11,  13],\n",
       "        [  6,  15,  18],\n",
       "        ...,\n",
       "        [  9,  23,  29],\n",
       "        [  9,  23,  29],\n",
       "        [ 17,  31,  37]],\n",
       "\n",
       "       [[  3,  15,  17],\n",
       "        [  0,  10,  12],\n",
       "        [  0,   8,  11],\n",
       "        ...,\n",
       "        [ 17,  31,  37],\n",
       "        [ 12,  26,  32],\n",
       "        [ 14,  28,  34]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지 읽어서 살펴보기\n",
    "import cv2\n",
    "\n",
    "# cv2.imread(file_name. flag) : 이미지를 읽어 Numpy 객체로 만듬\n",
    "# IMREAD_COLOR : color, 투명한 부분 무시\n",
    "# IMREAD_GRAYSCALE : grayscale\n",
    "# IMREAD_UNCHANGED : color, 투명한 부분도 읽기\n",
    "\n",
    "# Numpy 객체로 반환(행, 열, 색상(BGR))\n",
    "\n",
    "cv2.imread('test.jpg') # COLOR 기본 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd964a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(title, image) : 특정한 이미지 화면에 출력\n",
    "# title : 윈도우 창의 제목\n",
    "# image : 출력할 이미지 객체\n",
    "\n",
    "\n",
    "# 이미지 불러오기\n",
    "img = cv2.imread('test.jpg')\n",
    "\n",
    "# 이미지 크기 조정\n",
    "resized_img = cv2.resize(img, (500, 500))  # (500, 500)은 원하는 크기\n",
    "\n",
    "# 이미지 표시하기\n",
    "cv2.imshow('image', resized_img)\n",
    "\n",
    "# 키 입력 대기 (0이면 키를 누를 때까지 계속 대기)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 모든 창 닫기\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "384d929e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv2.imwrite(file_name, image) : 특정한 이미지를 파일로 저장하는 함수\n",
    "# file_name : 저장할 이미지 파일 이름\n",
    "# image : 저장할 이미지 객체\n",
    "\n",
    "cv2.imwrite('test_img.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86d4379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.waitKey(time) : 키보드 입력 처리하는 함수\n",
    "# time : 입력 대기 시간(무한대기 : 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e6bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.destroyAllWindows() : 화면의 모든 윈도우를 닫는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5741d5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b8143f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 35.2ms\n",
      "Speed: 2.5ms preprocess, 35.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.6ms\n",
      "Speed: 1.3ms preprocess, 33.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 35.2ms\n",
      "Speed: 1.0ms preprocess, 35.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 35.2ms\n",
      "Speed: 1.1ms preprocess, 35.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.2ms\n",
      "Speed: 2.0ms preprocess, 34.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 35.2ms\n",
      "Speed: 1.5ms preprocess, 35.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.9ms\n",
      "Speed: 1.1ms preprocess, 33.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.0ms\n",
      "Speed: 1.1ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.1ms\n",
      "Speed: 1.2ms preprocess, 34.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.2ms\n",
      "Speed: 1.0ms preprocess, 34.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.6ms\n",
      "Speed: 1.2ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 32.8ms\n",
      "Speed: 1.0ms preprocess, 32.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 36.7ms\n",
      "Speed: 2.0ms preprocess, 36.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.7ms\n",
      "Speed: 1.0ms preprocess, 33.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 36.7ms\n",
      "Speed: 2.0ms preprocess, 36.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 35.6ms\n",
      "Speed: 1.9ms preprocess, 35.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 35.7ms\n",
      "Speed: 1.5ms preprocess, 35.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.3ms\n",
      "Speed: 1.5ms preprocess, 34.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 37.9ms\n",
      "Speed: 1.0ms preprocess, 37.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 36.1ms\n",
      "Speed: 1.0ms preprocess, 36.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 36.6ms\n",
      "Speed: 1.0ms preprocess, 36.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 35.6ms\n",
      "Speed: 3.0ms preprocess, 35.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.2ms\n",
      "Speed: 0.0ms preprocess, 34.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.8ms\n",
      "Speed: 1.0ms preprocess, 33.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.7ms\n",
      "Speed: 1.0ms preprocess, 33.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 37.7ms\n",
      "Speed: 1.0ms preprocess, 37.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.1ms\n",
      "Speed: 1.5ms preprocess, 34.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 36.0ms\n",
      "Speed: 1.5ms preprocess, 36.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 36.2ms\n",
      "Speed: 0.9ms preprocess, 36.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.9ms\n",
      "Speed: 1.0ms preprocess, 33.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 41.6ms\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 36.6ms\n",
      "Speed: 1.0ms preprocess, 36.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.7ms\n",
      "Speed: 1.0ms preprocess, 34.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 38.2ms\n",
      "Speed: 1.5ms preprocess, 38.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 35.8ms\n",
      "Speed: 1.1ms preprocess, 35.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 40.3ms\n",
      "Speed: 2.0ms preprocess, 40.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 40.6ms\n",
      "Speed: 1.5ms preprocess, 40.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 35.7ms\n",
      "Speed: 1.0ms preprocess, 35.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.4ms\n",
      "Speed: 1.0ms preprocess, 34.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.3ms\n",
      "Speed: 1.0ms preprocess, 34.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.7ms\n",
      "Speed: 1.0ms preprocess, 34.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 36.7ms\n",
      "Speed: 1.0ms preprocess, 36.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.2ms\n",
      "Speed: 0.0ms preprocess, 34.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 36.7ms\n",
      "Speed: 1.0ms preprocess, 36.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 32.7ms\n",
      "Speed: 1.0ms preprocess, 32.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.2ms\n",
      "Speed: 1.5ms preprocess, 33.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 32.8ms\n",
      "Speed: 1.0ms preprocess, 32.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 36.8ms\n",
      "Speed: 1.1ms preprocess, 36.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.4ms\n",
      "Speed: 0.0ms preprocess, 33.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.2ms\n",
      "Speed: 1.0ms preprocess, 34.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 43.2ms\n",
      "Speed: 1.0ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.1ms\n",
      "Speed: 1.0ms preprocess, 34.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 32.8ms\n",
      "Speed: 1.0ms preprocess, 32.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 36.1ms\n",
      "Speed: 1.0ms preprocess, 36.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 32.2ms\n",
      "Speed: 1.0ms preprocess, 32.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 35.1ms\n",
      "Speed: 1.0ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.2ms\n",
      "Speed: 1.5ms preprocess, 34.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.2ms\n",
      "Speed: 1.0ms preprocess, 34.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 32.7ms\n",
      "Speed: 1.0ms preprocess, 32.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.6ms\n",
      "Speed: 0.5ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 35.6ms\n",
      "Speed: 1.0ms preprocess, 35.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 35.6ms\n",
      "Speed: 1.0ms preprocess, 35.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.3ms\n",
      "Speed: 1.0ms preprocess, 33.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.6ms\n",
      "Speed: 1.5ms preprocess, 34.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 34.6ms\n",
      "Speed: 1.0ms preprocess, 34.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 32.7ms\n",
      "Speed: 1.0ms preprocess, 32.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.2ms\n",
      "Speed: 1.0ms preprocess, 33.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 32.2ms\n",
      "Speed: 1.0ms preprocess, 32.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 32.7ms\n",
      "Speed: 1.0ms preprocess, 32.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.2ms\n",
      "Speed: 1.0ms preprocess, 33.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.3ms\n",
      "Speed: 1.0ms preprocess, 33.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected Labels: {'person'}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLO 모델 로드\n",
    "model = YOLO('yolov9s.pt')\n",
    "\n",
    "# 웹캠 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('ERROR : Could not open webcam.')\n",
    "    exit()\n",
    "    \n",
    "# 중복없이 탐지된 라벨을 저장할 집합(set)\n",
    "detected_labels = set()\n",
    "\n",
    "while True:\n",
    "    # 프레임 읽기\n",
    "    ret, frame = cap.read() # ret : 프레임이 성공적으로 읽혔으면 True, 아니면 False\n",
    "                            # frame : 캡처된 프레임 자체, 이미지로 Numpy 배열로 표현\n",
    "    if not ret:\n",
    "        print('ERROR : Could not read frame.')\n",
    "        break\n",
    "    \n",
    "    # 객체 탐지 수행\n",
    "    results = model.predict(frame, conf=0.5) # conf : 신뢰도가 0.5이상인 경우 탐지된 것으로 간주\n",
    "    \n",
    "    # 예측 결과를 프레임에 그리기 및 집합에 라벨 추가\n",
    "    for result in results:\n",
    "        for box in result.boxes: # result.boxes : 객체 탐지 모델이 탐지한 각 객체의 경계 상자(좌표)\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0]) # x1, y1 : 왼쪽 상단 좌표, x2, y2 : 오른쪽 하단 좌표, 정수 변환\n",
    "            conf = box.conf[0]                     # 실제로 해당 클래스에 속할 확률을 나타내는 신뢰도\n",
    "            label = result.names[int(box.cls[0])]  # 예측된 클래스의 ID\n",
    "            \n",
    "            # 바운딩 박스와 레이블 그리기\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) \n",
    "            # 사각형(바운딩 박스)그림, 왼쪽상단 좌표, \n",
    "            # 오른쪽 하단 좌표, 사각형의 색상, 선의 두께\n",
    "            cv2.putText(frame, f'{label} {conf:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            # 탐지된 객체의 레이블과 신뢰도 출력, \n",
    "            # 객체의 레이블, 신뢰도, 텍스트를 그릴 위치, 사용할 글꼴, 글꼴 크기, 텍스트 색상, 선의 두께\n",
    "            \n",
    "            # 탐지된 라벨 집합에 추가(중복 제거)\n",
    "            detected_labels.add(label)\n",
    "            \n",
    "    # 결과 프레임을 화면에 표시\n",
    "    cv2.imshow('YOLO Test Screen', frame)\n",
    "        \n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 리소스 해제\n",
    "cap.release() # 웹캠 사용된 리소스 해제\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 탐지된 라벨 출력\n",
    "print('Detected Labels:', detected_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "438517e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지의 인덱스, 이미지 크기, 탐지된 객체의 수와 종류, 이미지 처리에 걸린시간\n",
    "# 이미지 전처리, 모델 추론, 결과 후처리에 걸린 시간 / 처리된 이미지의 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9657881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
