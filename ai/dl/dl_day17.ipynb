{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1DH-KS5nVCWRoLS0h3beHdhqloWlngiUe","authorship_tag":"ABX9TyOWfSf9KWvsccvKwZXhrakQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"rsIejvJIDap_","executionInfo":{"status":"ok","timestamp":1721784550900,"user_tz":-540,"elapsed":11561,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"outputs":[],"source":["from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing import image\n","from keras.applications import imagenet_utils\n","from keras.applications import vgg16\n","from keras.applications import mobilenet\n","from tensorflow.keras.optimizers import Adam, SGD\n","from keras.metrics import categorical_crossentropy\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","source":["train_path  = '/content/drive/MyDrive/dl_data/0724/train'\n","valid_path  = '/content/drive/MyDrive/dl_data/0724/valid'\n","test_path  = '/content/drive/MyDrive/dl_data/0724/test'"],"metadata":{"id":"NcdXiPnOJTfX","executionInfo":{"status":"ok","timestamp":1721784550900,"user_tz":-540,"elapsed":2,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["train_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(\n","    train_path, target_size=(224,224), batch_size=30)\n","valid_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(\n","    valid_path, target_size=(224,224), batch_size=30)\n","test_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(\n","    test_path, target_size=(224,224), batch_size=30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EB0bL114JTb3","executionInfo":{"status":"ok","timestamp":1721784589008,"user_tz":-540,"elapsed":2681,"user":{"displayName":"유윤태","userId":"14027048565102297286"}},"outputId":"72ddeea8-22e9-4617-c2fb-aea7f182e6d8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 202 images belonging to 2 classes.\n","Found 103 images belonging to 2 classes.\n","Found 451 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["base_model = vgg16.VGG16(weights = \"imagenet\", include_top=False, input_shape = (224,224, 3))\n","base_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x60r9-i3JrkA","executionInfo":{"status":"ok","timestamp":1721784592992,"user_tz":-540,"elapsed":2574,"user":{"displayName":"유윤태","userId":"14027048565102297286"}},"outputId":"ce6833e9-2903-4c20-dd63-e528eab1cd88"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14714688 (56.13 MB)\n","Trainable params: 14714688 (56.13 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n","from keras.models import Model"],"metadata":{"id":"pBPxkilTNyKT","executionInfo":{"status":"ok","timestamp":1721784592992,"user_tz":-540,"elapsed":10,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["last_layer = base_model.get_layer('block5_pool')"],"metadata":{"id":"UsBvOgi5Rv3i","executionInfo":{"status":"ok","timestamp":1721784592992,"user_tz":-540,"elapsed":9,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["last_output = last_layer.output"],"metadata":{"id":"dSe_1U5-R_5p","executionInfo":{"status":"ok","timestamp":1721784592993,"user_tz":-540,"elapsed":10,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["x = Flatten()(last_output)"],"metadata":{"id":"q7lIudMRSLwe","executionInfo":{"status":"ok","timestamp":1721784592993,"user_tz":-540,"elapsed":10,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["x = Dense(64, activation='relu', name='FC_2')(x)\n","x = BatchNormalization()(x) # 배치 단위로 데이터를 정규화 -> 안정적인 학습\n","x = Dropout(0.5)(x) # 과적합을 줄이기 위함"],"metadata":{"id":"f5kTlElBSZJ8","executionInfo":{"status":"ok","timestamp":1721784592993,"user_tz":-540,"elapsed":10,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["x = Dense(2, activation='softmax', name='softmax')(x)\n","# 개/고양이 분류기"],"metadata":{"id":"qTG8YRdISp-G","executionInfo":{"status":"ok","timestamp":1721784592993,"user_tz":-540,"elapsed":10,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["new_model = Model(inputs=base_model.input, outputs=x)"],"metadata":{"id":"dZe4xLj3S_vR","executionInfo":{"status":"ok","timestamp":1721784592993,"user_tz":-540,"elapsed":9,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["new_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qo6i0C8dTEKP","executionInfo":{"status":"ok","timestamp":1721784592993,"user_tz":-540,"elapsed":9,"user":{"displayName":"유윤태","userId":"14027048565102297286"}},"outputId":"2647cb89-7717-415b-cc01-9b4127133d0f"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," FC_2 (Dense)                (None, 64)                1605696   \n","                                                                 \n"," batch_normalization (Batch  (None, 64)                256       \n"," Normalization)                                                  \n","                                                                 \n"," dropout (Dropout)           (None, 64)                0         \n","                                                                 \n"," softmax (Dense)             (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 16320770 (62.26 MB)\n","Trainable params: 16320642 (62.26 MB)\n","Non-trainable params: 128 (512.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["new_model.compile(Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"RMQR-BgsTPfb","executionInfo":{"status":"ok","timestamp":1721784592993,"user_tz":-540,"elapsed":2,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["new_model.fit_generator(train_batches, steps_per_epoch=4,\n","                   validation_data=valid_batches, validation_steps=2, epochs=20, verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3E0sYt91Tc0G","executionInfo":{"status":"ok","timestamp":1721784744333,"user_tz":-540,"elapsed":151342,"user":{"displayName":"유윤태","userId":"14027048565102297286"}},"outputId":"0607b4c9-9b8c-43ec-aec5-08544c63a4ec"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-6c0f84f949e8>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  new_model.fit_generator(train_batches, steps_per_epoch=4,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","4/4 - 77s - loss: 1.1574 - accuracy: 0.5357 - val_loss: 2.0405 - val_accuracy: 0.7167 - 77s/epoch - 19s/step\n","Epoch 2/20\n","4/4 - 9s - loss: 0.7295 - accuracy: 0.6750 - val_loss: 1.1946 - val_accuracy: 0.7833 - 9s/epoch - 2s/step\n","Epoch 3/20\n","4/4 - 3s - loss: 0.4436 - accuracy: 0.7946 - val_loss: 2.6442 - val_accuracy: 0.7000 - 3s/epoch - 768ms/step\n","Epoch 4/20\n","4/4 - 2s - loss: 0.3224 - accuracy: 0.8667 - val_loss: 1.6732 - val_accuracy: 0.7500 - 2s/epoch - 585ms/step\n","Epoch 5/20\n","4/4 - 2s - loss: 0.2976 - accuracy: 0.8917 - val_loss: 3.9569 - val_accuracy: 0.7167 - 2s/epoch - 616ms/step\n","Epoch 6/20\n","4/4 - 3s - loss: 0.2913 - accuracy: 0.8833 - val_loss: 2.5170 - val_accuracy: 0.7167 - 3s/epoch - 654ms/step\n","Epoch 7/20\n","4/4 - 2s - loss: 0.2112 - accuracy: 0.8929 - val_loss: 1.3044 - val_accuracy: 0.8167 - 2s/epoch - 583ms/step\n","Epoch 8/20\n","4/4 - 2s - loss: 0.2078 - accuracy: 0.9083 - val_loss: 1.5756 - val_accuracy: 0.7833 - 2s/epoch - 624ms/step\n","Epoch 9/20\n","4/4 - 2s - loss: 0.3014 - accuracy: 0.8750 - val_loss: 1.3106 - val_accuracy: 0.7833 - 2s/epoch - 614ms/step\n","Epoch 10/20\n","4/4 - 2s - loss: 0.2039 - accuracy: 0.9083 - val_loss: 1.5132 - val_accuracy: 0.7333 - 2s/epoch - 610ms/step\n","Epoch 11/20\n","4/4 - 2s - loss: 0.0954 - accuracy: 0.9464 - val_loss: 0.9495 - val_accuracy: 0.8167 - 2s/epoch - 603ms/step\n","Epoch 12/20\n","4/4 - 3s - loss: 0.1105 - accuracy: 0.9833 - val_loss: 5.6942 - val_accuracy: 0.5167 - 3s/epoch - 643ms/step\n","Epoch 13/20\n","4/4 - 3s - loss: 0.1227 - accuracy: 0.9500 - val_loss: 1.4984 - val_accuracy: 0.8333 - 3s/epoch - 629ms/step\n","Epoch 14/20\n","4/4 - 2s - loss: 0.0613 - accuracy: 0.9750 - val_loss: 1.0758 - val_accuracy: 0.7833 - 2s/epoch - 609ms/step\n","Epoch 15/20\n","4/4 - 2s - loss: 0.0631 - accuracy: 0.9821 - val_loss: 0.9123 - val_accuracy: 0.8333 - 2s/epoch - 592ms/step\n","Epoch 16/20\n","4/4 - 3s - loss: 0.0264 - accuracy: 0.9917 - val_loss: 1.9060 - val_accuracy: 0.7167 - 3s/epoch - 637ms/step\n","Epoch 17/20\n","4/4 - 2s - loss: 0.0458 - accuracy: 0.9833 - val_loss: 0.9692 - val_accuracy: 0.8000 - 2s/epoch - 587ms/step\n","Epoch 18/20\n","4/4 - 2s - loss: 0.0506 - accuracy: 0.9821 - val_loss: 0.9088 - val_accuracy: 0.8667 - 2s/epoch - 579ms/step\n","Epoch 19/20\n","4/4 - 2s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.7930 - val_accuracy: 0.8333 - 2s/epoch - 589ms/step\n","Epoch 20/20\n","4/4 - 2s - loss: 0.0787 - accuracy: 0.9833 - val_loss: 0.9214 - val_accuracy: 0.8000 - 2s/epoch - 609ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7de0dc10be80>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["def load_dataset(path):\n","    data = load_files(path)\n","    paths = np.array(data['filenames'])\n","    targets = np_utils.to_categorical(np.array(data['target']))\n","    return paths, targets"],"metadata":{"id":"T0ic9ZE0TrLJ","executionInfo":{"status":"ok","timestamp":1721784744334,"user_tz":-540,"elapsed":5,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["from sklearn.datasets import load_files\n","# from keras.utils import np_utils\n","# 에러 발생시\n","# from tf.keras.utils import np_utils\n","# from tensorflow.keras.utils import np_utils\n","import numpy as np\n","test_files, test_targets = load_dataset('/content/drive/MyDrive/dl_data/0724/test')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":410},"id":"uTX7Pt0eUe_y","executionInfo":{"status":"error","timestamp":1721784853514,"user_tz":-540,"elapsed":320,"user":{"displayName":"유윤태","userId":"14027048565102297286"}},"outputId":"6265a0d3-af24-47c8-9b02-aa7273be37e0"},"execution_count":19,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'tf'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-14540ad9e087>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# from keras.utils import np_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 에러 발생시\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# from tensorflow.keras.utils import np_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["from keras.preprocessing import image\n","from keras.applications.vgg16 import preprocess_input\n","from tqdm import tqdm\n","def path_to_tensor(img_path):\n","    # loads RGB image as PIL.Image.Image type\n","    img = image.load_img(img_path, target_size=(224, 224))\n","    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n","    x = image.img_to_array(img)\n","    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n","    return np.expand_dims(x, axis=0)\n","def paths_to_tensor(img_paths):\n","    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n","    return np.vstack(list_of_tensors)\n","test_tensors = preprocess_input(paths_to_tensor(test_files))"],"metadata":{"id":"6E5K2AzXUfaf","executionInfo":{"status":"aborted","timestamp":1721784744334,"user_tz":-540,"elapsed":3,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('\\nTesting loss: {:.4f}\\nTesting accuracy: {:.4f}'.format(*new_model.evaluate(test_tensors, test_targets)))"],"metadata":{"id":"3UWrnHEiU3E7","executionInfo":{"status":"aborted","timestamp":1721784744334,"user_tz":-540,"elapsed":3,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# evaluate and print test accuracy\n","score = new_model.evaluate(test_tensors, test_targets)\n","print('\\n', 'Test accuracy:', score[1])"],"metadata":{"id":"7SNkBQg4U6t-","executionInfo":{"status":"aborted","timestamp":1721784744334,"user_tz":-540,"elapsed":3,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"m8TquZ1tU7uH","executionInfo":{"status":"aborted","timestamp":1721784744334,"user_tz":-540,"elapsed":3,"user":{"displayName":"유윤태","userId":"14027048565102297286"}}},"execution_count":null,"outputs":[]}]}